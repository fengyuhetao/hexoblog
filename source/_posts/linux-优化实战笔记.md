---
title: linux-优化实战笔记
tags: linux
abbrlink: 46756
date: 2018-12-04 10:24:03
---

​	这几年，写的代码基本都是本地跑，也没碰到什么性能问题。不过，实习的时候，网站三天两头就崩溃，看代码也似乎没啥问题，现在想想，我的解决方案无非重启，继续运行，崩溃了，继续重启，要是虚拟机有毛病，直接重装虚拟机，传说中的3R工程师（replace, reinstall, restart）。。。。。当时，这些问题基本都是技术老大处理，我也接触不到，怎么搞定的一无所知。

​	希望《linux性能优化》能给我带来一些新的知识面。

## 平均负载

### 概念

平均负载是指单位时间内，系统处于**可运行状态**和**不可中断状态**的平均进程数，也就是平均活跃进程数，和CPU使用率无直接关系。

* 可运行状态 指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们ps命令中处于R（Runnning）状态的进程

* 不可中断状态 正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如等待硬件设备的I/O相应，也就是ps命令中的D（Uninterruptible Sleep也叫做Disk Sleep）状态

### 查看

理想状态: 每个cpu运行一个进程。

主要就是top和uptime命令:

```
tiandiwuji@tiandiwuji:~/Desktop/linux_preformance$ uptime
 22:01:35 up 1 day, 19:23,  1 user,  load average: 0.00, 0.02, 0.00
```

load average: 分别是1分钟，5分钟，15分钟。考虑性能问题，应根据趋势来判断。

生产环境中，当平均负载高于CPU数量70%（不绝对），就需要开始关注分析。

最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。

注意：平局负载只能表现出性能出现问题，具体哪出现问题无法提供。

### 平均负载与CPU使用率

CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载不完全对应。

* CPU 密集型进程，使用大量 CPU 会导致平均负载升高         -->  一致
* I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU使用率不一定高。       --> 不一致
* 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU使用率也会偏高。      --> 不一致

### 案例分析

使用工具: stress和sysstat

stree: 系统压力测试工具

sysstat:Linux性能工具。

* mpstat 常用多核CPU性能分析工具，实时查看每个CPU的性能指标以及所有CPU的平均指标
* pidstat 常用进程性能分析工具，用来实时查看进程的CPU、内存、I/O以及上下文切换等性能指标

过程:

略

## CPU上下文切换

### 概念

#### CPU上下文:

CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是**CPU寄存器和程序计数器(PC)**,CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU 上下文。

**Note: x86 系统中自增的是 IP，用 CS:IP 组合表示正在执行的指令地址，此时 PC 只是一个概念上的说法。在 ARM 体系中 R15 就是 PC，当然 ARM 和 IA-32、x64 都支持高级内存管理，所以「PC」的内容未必是当前指令在内存中的绝对位置。**

#### 操作系统管理的任务

任务就是进程，或者说任务就是线程。是的，进程和线程正是最常见的任务。但是除此之外，还有没有其他的任务呢？硬件通过触发信号，会导致中断处理程序的调用，也是一种常见的任务。

#### CPU上下文切换

先把前一个任务的CPU上下文（也就是CPU寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后在跳转到程序计数器所指的新闻纸，运行新任务。*可参考SROP-study深入理解。*

根据操作系统管理的任务不同，CPU的上下文切换可以分布两个不同的场景，也就是**进程上下文切换、线程上下文切换、以及中断上下文切换**

### 进程上下文切换

#### 前置知识:

Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间， CPU 特权等级的 Ring 0 和 Ring 3。Ring0权限最高，Ring3最小，只能访问受限资源，不能访问内存等硬件设备，必须通过系统调用陷入内核中，才能访问特权资源。

进程既会在用户空间运行，也会在内核空间运行。进程在用户控件运行时，被称为进程的用户态，陷入内核空间时，成为进程的内核态。

从用户态到内核态的转变，需要系统调用来完成，查看文件就需要多次系统调用，1. 调用open() 打开文件 2.调用read()读取文件，并调用write()将内容写入到标准输出 3.调用close()关闭文件。

系统调用时，会发生CPU上下文切换。系统调用开始，保存当前用户态上下文，然后更新为内核态指令的新位置，最后跳转到内核态运行内核任务，系统调用后，则反之。所以，一次系统调用，发生两次CPU上下文切换。

注意:

系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的：

* 进程上下文切换，从一个进程切换到另一个进程进行

* 系统调用过程中一直是同一个进程中进行。

所以系统调用过程通常称为特权模式切换，而不是上下文切换。但是，事实上，系统调用过程中，CPU的上下文切换还是无法避免。

系统调用指令:

* 快速系统调用指令。32位系统使用sysenter指令，64位系统使用syscall指令。
* 软中断“int 0x80”机制，早期2.6内核及其以前的版本，才用软中断机制进行系统调用。因为软中断机制性能较差

#### 进程上下文切换和系统调用的区别

进程由内核管理和调度，进程切换只能在内核态中进行，所以，进程上下文不仅包括虚拟内存、栈、全局变量等用户空间的资源，还包括内核堆栈、寄存器等内核空间的状态。

因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。

![](/assets/linux/395666667d77e718da63261be478a96b.png)

根据Tsuna的测试报告，基本上每次上下文切换需要几十纳秒到数微妙的CPU时间。

另外，我们知道， Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。

进程什么时候会被调度到CPU上运行:

1. 进程执行完毕，从就绪队列里，调用其他进程
2. 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
3. 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
4. 当进程通过睡眠函数  sleep 这样的方法将自己主动挂起时，自然也会重新调度。
5. 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。
6. 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

### 线程上下文切换

**线程是调度的基本单位，而进程则是资源拥有的基本单位。**。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以，对于线程和进程，我们可以这么理解：

* 当进程只有一个线程时，可以认为进程就等于线程。
* 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。
* 线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。

线程上下文切换：

* 前后两个线程属于不同进程。此时，因为资源不共享，切换过程就跟进程上下文切换一样。
* 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

**Note: 虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。**

### 中断上下文切换

中断处理会打断进程的正常调度和执行,来快速响应硬件的事件，转而调用中断处理程序，响应设备事件。

跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。

对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。

## 如何查看CPU上下文切换状况

### 工具: 

#### vmstat： 

用于分析系统内存的使用情况，也用来分析CPU上下文切换和终端次数

```
tiandiwuji@tiandiwuji:~$ vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 1736052 114604 1011184    0    0    46    23   34   48  0  0 98  1  0
```

含义:（具体可通过`man vmstat`查看）

* cs(context switch) 每秒上下文切换次数

* in(interrupt) 每秒中断次数
* r(Running or Runnable) 就绪队列长度，也就是正在运行和等待CPU的进程数
* b(Blocked) 处于不可中断睡眠状态的进程数

#### pidstat

通过-w选项，可以查看每个进程上下文切换的状况。

```
tiandiwuji@tiandiwuji:~$ pidstat -w 5
Linux 4.15.0-42-generic (tiandiwuji) 	12/10/2018 	_x86_64_	(4 CPU)

09:08:06 AM   UID       PID   cswch/s nvcswch/s  Command
09:08:11 AM     0         1     47.21      0.00  systemd
09:08:11 AM     0         8     45.02      0.00  rcu_sched
09:08:11 AM     0        11      0.40      0.00  watchdog/0
09:08:11 AM     0        14      0.40      0.00  watchdog/1
09:08:11 AM     0        20      0.40      0.00  watchdog/2
09:08:11 AM     0        26      0.40      0.00  watchdog/3
09:08:11 AM     0        28      0.20      0.00  ksoftirqd/3
09:08:11 AM     0        35      1.79      0.00  kworker/2:1
09:08:11 AM     0        42      0.20      0.00  khugepaged
```

重要参数:

* cswch: 每秒自愿上下文切换（voluntary context switches）的次数
* nvcswch: 每秒非自愿上下文切换（non voluntary context switches）的次数

**自愿上下文切换**，是指进程无法获取所需资源，导致的上下文切换。I/O、内存等系统资源不足时，就会发生自愿上下文切换。

**非自愿上下文切换**，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

#### sysbench

多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况。

案例分析:

略。

## 某个CPU使用率达到100%

### CPU使用率

CPU 使用率是单位时间内 CPU 使用情况的统计，以百分比的形式显示。

CPU的时间会被分为很短的时间片，有调度器调度给各任务使用。

Linux定义节拍率，触发时间中断，并通过全局变量Jiffies记录开机以来的节拍数。

节拍率HZ是内核可配置选项。用户程序无法访问，内核还提供用户空间节拍率USER_HZ，固定位100.

```
root@tiandiwuji:/home/tiandiwuji# grep 'CONFIG_HZ=' /boot/config-$(uname -r)
CONFIG_HZ=250
```

/proc/stat 提供系统的CPU和任务的统计信息。

```
root@tiandiwuji:/home/tiandiwuji# cat /proc/stat | grep ^cpu
cpu  44665 3585 162408 2374608 26212 0 839 0 0 0
cpu0 11846 651 40882 592547 6989 0 204 0 0 0
cpu1 10418 1059 40370 594949 6362 0 87 0 0 0
cpu2 11638 551 40506 593987 6458 0 290 0 0 0
cpu3 10762 1323 40648 593124 6401 0 257 0 0 0
```

含义:

<ul>
<li>
<p>user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。</p>
</li>
<li>
<p>nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。</p>
</li>
<li>
<p>system（通常缩写为 sys），代表内核态 CPU 时间。</p>
</li>
<li>
<p>idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）。</p>
</li>
<li>
<p>iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间。</p>
</li>
<li>
<p>irq（通常缩写为 hi），代表处理硬中断的 CPU 时间。</p>
</li>
<li>
<p>softirq（通常缩写为 si），代表处理软中断的 CPU 时间。</p>
</li>
<li>
<p>steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。</p>
</li>
<li>
<p>guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。</p>
</li>
<li>
<p>guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间。</p>
</li>
</ul>

**CPU使用率 = ( 1 - 空闲时间 / 总CPU时间)**

一般会间隔一段时间取两次值，计算平均CPU使用率

**平局CPU使用率 = 1 - ((新空闲时间 - 旧空闲时间) / (新总CPU时间 / 旧总CPU时间))**

### 查看CPU使用率

* top 显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况。

* ps 则只显示了每个进程的资源使用情况。

top指令空白行之后是进程的实时信息，每一行的%cpu列，表示进程CPU使用率，包括用户态和内核态CPU使用率之和，包括进程用户空间使用的CPU、通过系统调用执行的内核CPU、以及在就绪队列等待运行的CPU。在虚拟化运行环境中，还包括运行虚拟机占用的CPU。

查看进程详细情况，包括用户态CPU和内核态CPU：

使用pidstat命令。`pidstat 1 5`

### CPU使用率过高

1. GDB 会中断程序运行，只适合性能分析后期，找到问题后，线下在调试
2. perf 内置性能分析工具，它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。

`perf top -g -p <pid>` :  对进程进行跟踪分析其调用

`perf top`，类似于 top，它能够实时显示占用 CPU，时钟最多的函数或者指令。

```
Samples: 1K of event 'cpu-clock', Event count (approx.): 276859353
Overhead  Shared Object                    Symbol
  38.00%  [kernel]                         [k] _raw_spin_unlock_irqrestore
  11.82%  [kernel]                         [k] vmw_cmdbuf_header_submit
   1.86%  [kernel]                         [k] __softirqentry_text_start
   1.11%  [kernel]                         [k] vsnprintf
   1.08%  libc-2.27.so                     [.] __strcmp_sse2_unaligned
   1.04%  [kernel]                         [k] format_decode
   1.01%  libc-2.27.so                     [.] _int_malloc
   0.79%  [kernel]                         [k] finish_task_switch
   0.79%  perf                             [.] 0x00000000001ea447
   0.69%  libgobject-2.0.so.0.5600.2       [.] g_type_check_instance_is_a
   0.67%  libc-2.27.so                     [.] malloc
   0.63%  [kernel]                         [k] exit_to_usermode_loop
   0.62%  [kernel]                         [k] kallsyms_expand_symbol.constprop.1
   0.60%  libmutter-clutter-2.so           [.] clutter_actor_is_visible
```

输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）。比如这个例子中，perf 总共采集了 833 个 CPU 时钟事件，而总事件数则为 97742399。**采样数需要我们特别注意.**,如果采样数过少，那么排序和百分比就没什么参考价值。

`perf record`可以实时展示系统性能信息，并保存数据，`perf report`用于解析展示`perf record`保存的数据。参数`-g`表示开启调用关系的采样。

案例:

略。

## CPU使用率很高，找不到高CPU的应用

系统的 CPU 使用率，不仅包括进程用户态和内核态的运行，还包括中断处理、等待 I/O 以及内核线程等。所以当发现系统的 CPU 使用率很高的时候，不一定能找到相对应的高CPU使用率的进程。

execsnoop 专为短时进程设计的工具。它通过 ftrace 实时监控进程的exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果。

https://github.com/brendangregg/perf-tools/blob/master/execsnoop

案例：略

## 系统中出现大量不可中断进程和僵尸进程

cpu使用类型除了用户CPU之外，还包括系统CPU（上下文切换），等待I/O的CPU（比如等待磁盘的响应）以及中断CPU（包括软中断和硬中断）等。

I/O的CPU（iowait）升高的问题：

当 iowait 升高时，进程很可能因为得不到硬件的响应，而长时间处于不可中断状态。从 ps 或者 top 命令的输出中，你可以发现它们都处于 D 状态，也就是不可中断状态（Uninterruptible Sleep）。

状态：

R： 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。

D：  是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。

Z：是 Zombie 的缩写，它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。

S:  是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。

I： 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。

T或者t: ，也就是 Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。

向一个进程发送 SIGSTOP 信号，它就会因响应这个信号变成暂停状态（Stopped）；再向它发送 SIGCONT 信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用 fg 命令，恢复到前台运行）。

而当你用调试器（如 gdb）调试一个进程时，在使用断点中断进程后，进程就会变成跟踪状态，这其实也是一种特殊的暂停状态，只不过你可以用调试器来跟踪并按需要控制进程的运行。

X：也就是 Dead 的缩写，表示进程已经消亡，所以你不会在 top 或者 ps 命令中看到它。

一旦父进程没有处理子进程的终止，使得子进程一直保持运行状态，那么子进程就会陷入僵尸状态。大量的僵尸进程会用尽PID进程号，导致新进程没有办法创建。

pid最大值：

```
$ cat /proc/sys/kernel/pid_max 
131072
```

案例:

dstat: 是一个新的性能工具，它吸收了 vmstat、iostat、ifstat 等几种工具的优点，可以同时观察系统的 CPU、磁盘 I/O、网络以及内存使用情况。

1. O_DIRECT 选项打开磁盘，于是绕过了系统缓存，直接对磁盘进行读写。容易导致 iowait升高
2. 正确处理子进程

```
int status = 0;
for (;;) {
	for (int i = 0; i < 2; i++) {
		if(fork()== 0) {
			sub_process(disk);
		}
	}

	sleep(5);
}

// 应该将该行放到for循环里
while(wait(&status)>0);
======================》
for (;;) {
		for (int i = 0; i < 2; i++) {
			if(fork()== 0) {
				sub_process(disk);
			}
		}

		while(wait(&status)>0);
		sleep(5);
	}
```

iowait 高不一定代表 I/O 有性能瓶颈。当系统中只有 I/O 类型的进程在运行时，iowait 也会很高，但实际上，磁盘的读写远没有达到性能瓶颈的程度。

僵尸进程出现的原因是父进程没有回收子进程的资源出现的。解决办法是找到父进程，在父进程中处理，使用pstree查父进程，然后查看父进程的源码检查wait()/waitpid()的调用或SIGCHLD信号处理函数的注册。

略。

## 怎么理解Linux软中断

进程的不可中断状态是系统的一种保护机制，可以保证硬件的交互过程不被意外打断。短时间的不可中断正常，长时间的不可中断，就需要确认是不是磁盘I/O的问题。

除了iowait,软中断(sftirq)CPU使用率升高也是常见的性能问题。

中断是系统用来相应硬件设备请求的一种机制，打断进程的正常调度和执行，然后在内核中的中断处理程序来响应设备的请求。

**中断其实也是一种异步的事件处理机制，可以提高系统的并发处理能力**

由于中断处理程序会打断正常程序的运行，所以**为了减少正常进程运行调度的影响，中断处理程序需要尽可能快地运行。**

中断处理程序在响应中断的时候，会临时关闭中断，会导致上一次中断处理完成之前，其他中断无法响应，若此期间有其他中断，该中断可能会丢失。

### 软中断

为了解决中断处理程序执行过长和中断丢失的问题，Linux 将中断处理过程分成了两个阶段，也就是**上半部和下半部**

* 上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。
* 下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行

以网卡为例:

网卡接收到数据包后，会通过**硬件中断**的方式，通知内核有新的数据到了。这时，内核就应该调用中断处理程序来响应它。对上半部来说，既然是快速处理，其实就是要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态（表示数据已经读好了），最后再发送一个**软中断**信号，通知下半部做进一步的处理。

1. 上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行；
2. 而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。

每个CPU对应一个软中断内核线程，名字"ksoftirqd/CPU编号"。通过ps，可以看到。

```
tiandiwuji@tiandiwuji:~$ ps -aux | grep softirq
root          7  0.0  0.0      0     0 ?        S    03:25   0:00 [ksoftirqd/0]
root         16  0.0  0.0      0     0 ?        S    03:25   0:00 [ksoftirqd/1]
root         22  0.0  0.0      0     0 ?        S    03:25   0:00 [ksoftirqd/2]
root         28  0.0  0.0      0     0 ?        S    03:25   0:00 [ksoftirqd/3]
```

除此以外，一些内核自定义的时间也属于软中断，比如内核调度和RCU锁(Read-Copy Update)的缩写，RCU是linux核最常用的锁之一。

### 查看软中断和内核线程

* /proc/softirqs 提供内核软中断运行情况
* /proc/interrupts 提供硬z中断的运行情况

```
tiandiwuji@tiandiwuji:~$ cat /proc/softirqs | awk '{print $1,$2,$3,$4,$5}'
          CPU0 CPU1 CPU2 CPU3 CPU4
HI:       0 0 1 0
TIMER:    113728 116472 129373 99897     # 定时
NET_TX:   1 2373 0 2                     # 网络接收中断
NET_RX:   150 345 235 36859              # 网络发送中断
BLOCK:    21437 52 13761 11537
IRQ_POLL: 0 0 0 0
TASKLET:  3 3642 36 60
SCHED:    108890 107750 120843 94838     # 调度
HRTIMER:  0 0 0 0
RCU:      122822 114064 107781 97828

```

第一列标识软中断的10个类别。正常情况下，每个cpu上的累计次数差不多。

TASKLET  在不同 CPU 上的分布并不均匀。TASKLET 是最常用的软中断实现机制，每个 TASKLET 只运行一次就会结束 ，并且只在调用它的函数所在的 CPU 上运行。

大量的网络小包会导致性能问题，可能是由于大量的小网络包会导致频繁的硬中断和软中断。

## 系统的软中断CPU使用率升高

sar: sar 是一个系统活动报告工具，既可以实时查看系统的当前活动，又可以配置保存和报告历史统计数据。

hping3: hping3 是一个可以构造 TCP/IP 协议数据包的工具，可以对系统进行安全审计、防火墙测试等。

tcpdump: tcpdump 是一个常用的网络抓包工具，常用来分析各种网络问题。

案例：

略。

## Linux内存是怎么工作的

### 虚拟内存

物理内存也成为主存，大多是动态随机访问内存（DRAM)。只有内核能够直接访问物理内存。

Linux为每个进程提供独立的虚拟地址空间，且连续。

虚拟地址空间被分为内核空间和用于空间，32位和64位系统地址空间范围不同。

![](/assets/linux/ed8824c7a2e4020e2fdd2a104c70ab7b.png)

具体版:

32位linux内核2.6.7以前默认布局：

![](/assets/linux/TIM截图20190103170730.png)

32位当前默认布局：

![](/assets/linux/TIM截图20190103170839.png)

64位默认布局：

![](/assets/linux/TIM截图20190103170947.png)

不同的进程都包含内核空间，但是这些内核空间均是相同的物理内存。进程切换到内核态之后，可以很方便的访问内核空间内存。

### 内存映射

将虚拟内存地址映射到物理地址内存：

![](/assets/linux/TIM截图20190103171140.png)

页表存储在CPU的内存管理单元MMU中，这样，正常情况下，处理器可以通过硬件找出要访问的内存。而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，，进入内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

Linux 通过 TLB（Translation Lookaside Buffer，转译后备缓冲器）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。原因如上。

TLB 其实就是 MMU 中页表的高速缓存。由于进程的虚拟地址空间是独立的，而 TLB 的访问速度又比 MMU 快得多，所以，通过减少进程的上下文切换，减少 TLB 的刷新次数，就可以提高 TLB 缓存的使用率，进而提高 CPU 的内存访问性能。不过要注意，MMU 并不以字节为单位来管理内存，而是规定了一个内存映射的最小单位，也就是页，通常是 4 KB 大小。这样，每一次内存映射，都需要关联 4 KB 或者 4KB 整数倍的内存空间。页的大小只有 4 KB ，导致的另一个问题就是，整个页表会变得非常大。比方说，仅 32 位系统就需要 100 多万个页表项（4GB/4KB），才可以实现整个地址空间的映射。为了解决页表项过多的问题，Linux 提供了两种机制，也就是多级页表和大页（HugePage）。

Linux 用的正是四级页表来管理内存页，如下图所示，虚拟地址被分为 5 个部分，前 4 个表项用于选择页，而最后一个索引表示页内偏移。

![](/assets/linux/b5c9179ac64eb5c7ca26448065728325.png)

### 内存分配与回收

#### 分配：

malloc是c标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，`brk()`和`mmap()`。

对于小块内存(小于128k)，采用brk分配，通过移动堆顶位置来分配，释放后不会立即归还，会被缓存起来。易产生内存碎片 。释放:`free()`

对于大块内存(大于128k)，直接使用内存映射mmap()分配，在文件映射端找一段空闲内存分配出去。释放后，直接归还系统，每次mmap都会发生缺页异常。易导致内核管理负担增大。释放: `unmap`

通过以上两种方式调用之后，不会立即分配物理内存，只有在首次访问时，才会分配，通过缺页异常进入内核，由内核分配内存。

在内核空间，Linux采用slab分配器管理小内存。可以把slab看成构建在伙伴系统上的一个缓存，主要作用就是分配并释放内核中的小对象。

#### 回收

* 回收缓存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面；
* 回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中；也就是swap（交换分区中）
* 杀死进程，内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程。

第三种方法是内核的一种保护机制，监控内存使用情况，并使用oom_score为每个进程的内存使用情况进行评分。

* 一个进程消耗的内存越大，oom_score 就越大；
* 一个进程运行占用的 CPU 越多，oom_score 就越小。

该值可通过`/proc`文件系统，手动设置进程的oom_adj，调整oom_score。oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；数值越小，表示进程越不容易被 OOM 杀死，其中 -17 表示禁止 OOM。

修改sshd进程的oom_score

```
echo -16 > /proc/$(pidof sshd)/oom_adj
```

### 查看内存使用情况

`free`

```
[root@iz2zehekqyjug6ar3u4omgz ~]# free
              total        used        free      shared  buff/cache   available
Mem:        1883724       79732      164524         356     1639468     1602056
Swap:             0           0           0
```

available 不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。

`top`,按`M`切换到内存内存排序

```
top - 17:47:49 up 46 days, 22:21,  2 users,  load average: 0.00, 0.01, 0.05
Tasks:  67 total,   2 running,  65 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.3 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  1883724 total,   162908 free,    79996 used,  1640820 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  1601808 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
  327 root      20   0   69684  30772  30460 S  0.0  1.6   0:15.87 systemd-journal
13420 root      20   0  293244  20100  16804 S  0.0  1.1   2:46.02 rsyslogd
13618 root      20   0  573752  17124   6108 S  0.0  0.9   6:49.66 tuned
  677 root      20   0  112876  12792    312 S  0.0  0.7   0:00.00 dhclient
 2148 root      20   0  129984  11608   9280 R  0.0  0.6 153:39.71 AliYunDun
13537 polkitd   20   0  538564  10364   4788 S  0.0  0.6   0:07.49 polkitd
16159 root      20   0  152540   5508   4212 S  0.0  0.3   0:00.01 sshd
16240 root      20   0  152540   5508   4212 S  0.0  0.3   0:00.03 sshd
 6159 root      20   0  112812   4312   3284 S  0.0  0.2   0:00.22 sshd
    1 root      20   0   43444   3664   2432 S  0.0  0.2   0:34.82 systemd
14443 nginx     20   0  121272   3576   1060 S  0.0  0.2   0:00.00 nginx
```

* VIRT:是进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。
* RES 是常驻内存的大小，也就是进程实际使用的物理内存大小，但不包括 Swap 和共享内存。
* SHR 是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等。
* %MEM 是进程使用物理内存占系统总内存的百分比。

注意:

1. 第一，虚拟内存通常并不会全部分配物理内存。从上面的输出，你可以发现每个进程的虚拟内存都比常驻内存大得多。
2. 共享内存 SHR 并不一定是共享的，比方说，程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。所以在计算多个进程的内存使用时，不要把所有进程的 SHR 直接相加得出结果。

## 怎么理解内存中的Buffer和Cache

buffer: 缓冲区。cache: 缓存。两者都是数据在内存中的临时存储。

free命令数据来源

* Buffers 是内核缓冲区用到的内存，对应的是  /proc/meminfo 中的 Buffers 值。
* Cache 是内核页缓存和 Slab 用到的内存，对应的是  /proc/meminfo 中的 Cached 与 SReclaimable 之和。

查看proc

* Buffers 是对原始磁盘块的临时存储，也就是用来**缓存磁盘的数据**,，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。

* Cached 是从磁盘读取文件的页缓存，也就是用来**缓存从文件读取的数据**,。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。\
* SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。

```
echo 3 >/proc/sys/vm/drop_caches
```

` /proc/sys/vm/drop_caches` ，这是通过 proc 文件系统修改内核行为的一个示例，写入 3 表示清理文件页、目录项、Inodes 等各种缓存。

写文件时会用到 Cache 缓存数据，而写磁盘则会用到 Buffer 来缓存数据。虽然文档上只提到，Cache 是文件读的缓存，但实际上，Cache 也会缓存写文件时的数据。同样，Buffer 既可以用作“将要写入磁盘数据的缓存”，也可以用作“从磁盘读取数据的缓存”。

**Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中**

注: linux中的块设备可以直接访问（比如数据库应用程序），也可以通过存储文件系统访问

## 利用系统缓存优化程序运行效率

**存的命中率**：是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。

安装cachestat, cachetop，这两工具均为bcc软件包的一部分。基于Linux内核的eBPF(extended Berkeley Packet Filters)机制，跟踪内核中管理的缓存，并输出缓存的使用和命中情况。

```
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD
echo "deb https://repo.iovisor.org/apt/xenial xenial main" | sudo tee /etc/apt/sources.list.d/iovisor.list
sudo apt-get update
sudo apt-get install -y bcc-tools libbcc-examples linux-headers-$(uname -r)
```

```
export PATH=$PATH:/usr/share/bcc/tools
```

安装pcstat:

```
$ export GOPATH=~/go
$ export PATH=~/go/bin:$PATH
$ go get golang.org/x/sys/unix
$ go get github.com/tobert/pcstat/pcstat
```

`go get golang.org/x/sys/unix` 报错:

```
package golang.org/x/sys/unix: unrecognized import path "golang.org/x/sys/unix" (https fetch: Get https://golang.org/x/sys/unix?go-get=1: dial tcp 216.239.37.1:443: getsockopt: connection refused)
```

解决方案:

```
$ mkdir -p $GOPATH/src/golang.org/x/
$ git clone https://github.com/golang/sys.git sys
$ go install golang.org/x/sys/unix
```

报错:

`undefined runtime.KeepAlive`,原因：

```
Sorry, Go 1.6 is no longer supported.

If you were using Go 1.6 for App Engine, note that GAE standard supports Go 1.9 (by default) now.
```

升级golang即可。

首先卸载go:

```
sudo apt-get remove golang-1.6
sudo apt-get install golang-1.9
```

注意，原来卸载之后并没有把这里的文件卸载干净，这里的可执行文件也没有变。需要先清空原先的go文件夹。 

```
cd /usr/lib
rm -rf go-1.6
rm -rf go
mkdir go
cp -r ./go-1.9/* ./go
```

配置环境变量:

```
在/etc/profile文件末尾添加，然后source /etc/profile
export GOPATH=/go
export GOROOT=/usr/local/go
export PATH=$PATH:$GOROOT/bin:$GOPATH/bin
```

### centos安装bcc-tools

```
[root@centos-80 ~]# yum update
[root@centos-80 ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org && rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm
[root@centos-80 ~]# uname -r ## 
3.10.0-862.el7.x86_64
[root@centos-80 ~]# yum remove kernel-headers kernel-tools kernel-tools-libs
[root@centos-80 ~]# yum --disablerepo="*" --enablerepo="elrepo-kernel" install kernel-ml kernel-ml-devel kernel-ml-headers kernel-ml-tools kernel-ml-tools-libs kernel-ml-tools-libs-devel 
[root@centos-80 ~]# sed -i '/GRUB_DEFAULT/s/=.*/=0/' /etc/default/grub
[root@centos-80 ~]# grub2-mkconfig -o /boot/grub2/grub.cfg
[root@centos-80 ~]# reboot
[root@centos-80 ~]# uname -r ## 升级成功
4.20.0-1.el7.elrepo.x86_64
[root@centos-80 ~]# yum install -y bcc-tools
[root@centos-80 ~]# echo 'export PATH=$PATH:/usr/share/bcc/tools' > /etc/profile.d/bcc-tools.sh
[root@centos-80 ~]# . /etc/profile.d/bcc-tools.sh
[root@centos-80 ~]# cachestat 1 1 ## 测试安装是否成功
TOTAL MISSES HITS DIRTIES BUFFERS_MB CACHED_MB
0 0 0 0 2 287
```

测试案例:

略。

## 内存分配

对普通进程来说，能看到的其实是内核提供的虚拟内存，这些虚拟内存还需要通过页表，由系统映射为物理内存。

当进程通过 malloc() 申请虚拟内存后，系统并不会立即为其分配物理内存，而是在首次访问时，才通过缺页异常陷入内核中分配内存。

为了协调 CPU 与磁盘间的性能差异，Linux 还会使用 Cache 和 Buffer ，分别把文件和磁盘读写的数据缓存到内存中。

内存泄漏:

* 没正确回收分配后的内存，导致了泄漏。
* 访问的是已分配内存边界外的地址，导致程序异常退出，等等。

用户空间内存包括多个不同的内存段，比如只读段、数据段、堆、栈以及文件映射段等。这些内存段正是应用程序使用内存的基本方式。

* 栈内存由系统自动分配和管理。一旦程序运行超出了这个局部变量的作用域，栈内存就会被系统自动回收，所以不会产生内存泄漏的问题。
* 使用标准库函数 malloc()在程序中动态分配内存。这时候，系统就会从内存空间的堆中分配内存。堆内存由应用程序自己来分配和管理。除非程序退出，这些堆内存并不会被系统自动释放，而是需要应用程序明确调用库函数 来释放它们。如果应用程序没有正确释放堆内存，就会造成内存泄漏。
* 只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。
* 数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。
* 最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。

虽然，系统最终可以通过 OOM （Out of Memory）机制杀死进程，但进程在 OOM 前，可能已经引发了一连串的反应，导致严重的性能问题。比如，其他需要内存的进程，可能无法分配新的内存；内存不足，又会触发系统的缓存回收以及 SWAP 机制，从而进一步导致 I/O 的性能问题等等。

案例实战:

检测内存泄漏的工具，memleak。memleak 可以跟踪系统或指定进程的内存分配、释放请求，然后定期输出一个未释放内存和相应调用栈的汇总情况（默认 5 秒）。

略